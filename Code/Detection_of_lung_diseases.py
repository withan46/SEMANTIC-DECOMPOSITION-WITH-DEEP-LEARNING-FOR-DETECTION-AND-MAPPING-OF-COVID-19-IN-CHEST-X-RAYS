# -*- coding: utf-8 -*-
"""fold 4 Detection of lung diseases

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1W_4NizGJp00qnZtFZqtWwVt6YMKQvQnl
"""

#import data from drive
from google.colab import drive
drive.mount('/content/drive')

import zipfile
import os
import numpy as np
import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array
import cv2
import numpy as np
from sklearn.model_selection import train_test_split
# Import the libraries
import zipfile
from google.colab import files

# import system libs
import os
import time
import shutil
import pathlib
import itertools

# import data handling tools
import cv2
import numpy as np
import pandas as pd
import seaborn as sns
sns.set_style('darkgrid')
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix, classification_report
from sklearn.metrics import classification_report, accuracy_score
from sklearn.model_selection import StratifiedKFold


# import Deep learning Libraries
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras.applications import VGG16
from tensorflow.keras.applications import ResNet50
from tensorflow.keras.models import Sequential
from tensorflow.keras.optimizers import Adamax
from tensorflow.keras.metrics import categorical_crossentropy
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Activation, Dropout, BatchNormalization
from tensorflow.keras import regularizers
from tensorflow.keras.preprocessing import image
from tensorflow.keras.applications.vgg16 import preprocess_input

# Ignore Warnings
import warnings
warnings.filterwarnings("ignore")

print ('modules loaded')

# Let's begin by adjusting the data handling to manage images and masks, and then set up the U-Net model.
from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping
from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, concatenate, Conv2DTranspose
from tensorflow.keras.models import Model
from tensorflow.keras.utils import Sequence
import numpy as np
import os
from tensorflow.keras.preprocessing.image import ImageDataGenerator
import os
import numpy as np
import pandas as pd
import cv2
from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, concatenate, Conv2DTranspose
from tensorflow.keras.models import Model
from tensorflow.keras.utils import Sequence
from tensorflow.keras.backend import flatten as K_flatten, sum as K_sum
from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, TensorBoard
from tensorflow.keras.preprocessing.image import ImageDataGenerator
import datetime

# Unzip the dataset
zip_ref = zipfile.ZipFile('/content/drive/MyDrive/Colab Notebooks/NeuralNetwork.zip', 'r')
zip_ref.extractall('/tmp')
zip_ref.close()

# Generate data paths with labels
# Prepare data paths and labels
def define_paths(data_dir):
    filepaths = []
    labels = []

    folds = os.listdir(data_dir)
    for fold in folds:
        foldpath = os.path.join(data_dir, fold)
        if pathlib.Path(foldpath).suffix != '':
            continue

        filelist = os.listdir(foldpath)
        for file in filelist:
            fpath = os.path.join(foldpath, file)
            if pathlib.Path(foldpath).suffix == '':
                if pathlib.Path(fpath).parts[-1].lower() == 'masks':
                    continue
                else:
                    o_file = os.listdir(fpath)
                    for f in o_file:
                        ipath = os.path.join(fpath, f)
                        filepaths.append(ipath)
                        labels.append(fold)
            else:
                filepaths.append(fpath)
                labels.append(fold)

    return filepaths, labels



# Concatenate data paths with labels into one dataframe ( to later be fitted into the model )
def define_df(files, classes):
  Fseries = pd.Series(files, name= 'filepaths')
  Lseries = pd.Series(classes, name='labels')
  return pd.concat([Fseries, Lseries], axis= 1)

# Split dataframe to train, valid, and test
def split_data(data_dir):


  random_state = 101


  # train dataframe
  files, classes = define_paths(data_dir)
  df = define_df(files, classes)
  strat = df['labels']
  train_df, dummy_df = train_test_split(df, train_size=0.8, shuffle=True, random_state=random_state, stratify=strat)

  # valid and test dataframe
  strat = dummy_df['labels']
  valid_df, test_df = train_test_split(dummy_df, train_size=0.5, shuffle=True, random_state=random_state, stratify=strat)

  return train_df, valid_df, test_df

def create_gens (train_df, valid_df, test_df, batch_size):
    '''
    This function takes train, validation, and test dataframe and fit them into image data generator, because model takes data from image data generator.
    Image data generator converts images into tensors. '''


    # define model parameters
    img_size = (256, 256)
    channels = 3 # BGR
    color = 'rgb'
    img_shape = (img_size[0], img_size[1], channels)

    # Test data custom batch size
    ts_length = len(test_df)
    test_batch_size = max(sorted([ts_length // n for n in range(1, ts_length + 1) if ts_length%n == 0 and ts_length/n <= 80]))
    test_steps = ts_length // test_batch_size

    # This function which will be used in image data generator for data augmentation, it just take the image and return it again.
    def scalar(img):
        return img

    tr_gen = ImageDataGenerator(preprocessing_function= scalar, horizontal_flip= True)
    ts_gen = ImageDataGenerator(preprocessing_function= scalar)

    train_gen = tr_gen.flow_from_dataframe( train_df, x_col= 'filepaths', y_col= 'labels', target_size= img_size, class_mode= 'categorical',
                                        color_mode= color, shuffle= True, batch_size= batch_size)

    valid_gen = ts_gen.flow_from_dataframe( valid_df, x_col= 'filepaths', y_col= 'labels', target_size= img_size, class_mode= 'categorical',
                                        color_mode= color, shuffle= True, batch_size= batch_size)

    # Note: we will use custom test_batch_size, and make shuffle= false
    test_gen = ts_gen.flow_from_dataframe( test_df, x_col= 'filepaths', y_col= 'labels', target_size= img_size, class_mode= 'categorical',
                                        color_mode= color, shuffle= False, batch_size= test_batch_size)

    return train_gen, valid_gen, test_gen



def show_images(gen):
    '''
    This function take the data generator and show sample of the images
    '''

    # return classes , images to be displayed
    g_dict = gen.class_indices        # defines dictionary {'class': index}
    classes = list(g_dict.keys())     # defines list of dictionary's kays (classes), classes names : string
    images, labels = next(gen)        # get a batch size samples from the generator

    # calculate number of displayed samples
    length = len(labels)        # length of batch size
    sample = min(length, 25)    # check if sample less than 25 images

    plt.figure(figsize= (20, 20))

    for i in range(sample):
        plt.subplot(5, 5, i + 1)
        image = images[i] / 255       # scales data to range (0 - 255)
        plt.imshow(image)
        index = np.argmax(labels[i])  # get image index
        class_name = classes[index]   # get class of image
        plt.title(class_name, color= 'blue', fontsize= 12)
        plt.axis('off')
    plt.show()

def plot_segmentation_training(hist):
    '''
    This function plots the training and validation loss, and the Dice coefficient for a segmentation model.
    '''

    # Define needed variables
    tr_loss = hist.history['loss']
    val_loss = hist.history['val_loss']
    tr_dice = hist.history.get('dice_coefficient')
    val_dice = hist.history.get('val_dice_coefficient')

    if not tr_dice or not val_dice:
        print("Dice coefficient not found in history. Ensure it's being tracked during training.")
        return

    index_loss = np.argmin(val_loss)
    val_lowest = val_loss[index_loss]
    index_dice = np.argmax(val_dice)
    dice_highest = val_dice[index_dice]
    epochs = [i + 1 for i in range(len(tr_loss))]
    loss_label = f'Best epoch= {str(index_loss + 1)}'
    dice_label = f'Best epoch= {str(index_dice + 1)}'

    # Plot training history for loss
    plt.figure(figsize=(20, 8))
    plt.style.use('fivethirtyeight')

    plt.subplot(1, 2, 1)
    plt.plot(epochs, tr_loss, 'r', label='Training loss')
    plt.plot(epochs, val_loss, 'g', label='Validation loss')
    plt.scatter(index_loss + 1, val_lowest, s=150, c='blue', label=loss_label)
    plt.title('Training and Validation Loss')
    plt.xlabel('Epochs')
    plt.ylabel('Loss')
    plt.legend()

    # Plot training history for Dice coefficient
    plt.subplot(1, 2, 2)
    plt.plot(epochs, tr_dice, 'r', label='Training Dice Coefficient')
    plt.plot(epochs, val_dice, 'g', label='Validation Dice Coefficient')
    plt.scatter(index_dice + 1, dice_highest, s=150, c='blue', label=dice_label)
    plt.title('Training and Validation Dice Coefficient')
    plt.xlabel('Epochs')
    plt.ylabel('Dice Coefficient')
    plt.legend()

    plt.tight_layout()
    plt.show()

def plot_confusion_matrix(cm, classes, normalize= False, title= 'Confusion Matrix', cmap= plt.cm.Blues):
	'''
	This function plot confusion matrix method from sklearn package.
	'''

	plt.figure(figsize= (10, 10))
	plt.imshow(cm, interpolation= 'nearest', cmap= cmap)
	plt.title(title)
	plt.colorbar()

	tick_marks = np.arange(len(classes))
	plt.xticks(tick_marks, classes, rotation= 45)
	plt.yticks(tick_marks, classes)

	if normalize:
		cm = cm.astype('float') / cm.sum(axis= 1)[:, np.newaxis]
		print('Normalized Confusion Matrix')

	else:
		print('Confusion Matrix, Without Normalization')

	print(cm)

	thresh = cm.max() / 2.
	for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):
		plt.text(j, i, cm[i, j], horizontalalignment= 'center', color= 'white' if cm[i, j] > thresh else 'black')

	plt.tight_layout()
	plt.ylabel('True Label')
	plt.xlabel('Predicted Label')

# data_dir = '/tmp/COVID-19_Radiography_Dataset'

# try:
#     # Get splitted data
#     train_df, valid_df, test_df = split_data(data_dir)

#     # Get Generators
#     batch_size = 16
#     train_gen, valid_gen, test_gen = create_gens(train_df, valid_df, test_df, batch_size)

# except:
#     print('Invalid Input')

# Custom Sequence class for image-mask pairs
class ImageMaskGenerator(Sequence):
    def __init__(self, df, batch_size=32, image_size=(256, 256), shuffle=True, seed=None):
        self.df = df
        self.batch_size = batch_size
        self.image_size = image_size
        self.shuffle = shuffle
        self.seed = seed
        self.indices = np.arange(len(self.df))
        if self.shuffle:
            np.random.seed(self.seed)
            np.random.shuffle(self.indices)

    def __len__(self):
        return int(np.ceil(len(self.df) / self.batch_size))

    def on_epoch_end(self):
        if self.shuffle: np.random.shuffle(self.indices)

    def __getitem__(self, index):
        start_idx = index * self.batch_size
        batch_indices = self.indices[start_idx:start_idx + self.batch_size]
        return self.__data_generation(batch_indices)

    def __data_generation(self, batch_indices):
        batch_images = np.empty((len(batch_indices), *self.image_size, 3), dtype=np.float32)
        batch_masks = np.empty((len(batch_indices), *self.image_size, 1), dtype=np.float32)

        for i, idx in enumerate(batch_indices):
            img_path = self.df.iloc[idx]['image']
            mask_path = self.df.iloc[idx]['mask']

            # Load image and mask
            image = cv2.imread(img_path)
            image = cv2.resize(image, self.image_size)
            image = image / 255.0  # Normalize to [0, 1]

            mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)
            mask = cv2.resize(mask, self.image_size)
            mask = mask[..., np.newaxis]  # Add channel dimension
            mask = mask / 255.0  # Normalize to [0, 1]

            batch_images[i] = image
            batch_masks[i] = mask

        return batch_images, batch_masks

# Prepare data paths and labels
def prepare_data(base_dir):
    categories = ['COVID', 'Normal']
    image_files = []
    mask_files = []
    labels = []

    for category in categories:
        image_dir = os.path.join(base_dir, category, 'images')
        mask_dir = os.path.join(base_dir, category, 'masks')
        images = sorted([os.path.join(image_dir, f) for f in os.listdir(image_dir) if f.endswith('.png')])
        masks = sorted([os.path.join(mask_dir, f) for f in os.listdir(mask_dir) if f.endswith('.png')])

        image_files.extend(images)
        mask_files.extend(masks)
        labels.extend([category] * len(images))

    df = pd.DataFrame({'image': image_files, 'mask': mask_files, 'category': labels})
    return df

# Split data into train, validation, and test sets
def prepare_and_split_data(df, test_size=0.1, val_size=0.1):
    train_val_df, test_df = train_test_split(df, test_size=test_size, random_state=101, stratify=df['category'])
    adjusted_val_size = val_size / (1 - test_size)
    train_df, val_df = train_test_split(train_val_df, test_size=adjusted_val_size, random_state=101, stratify=train_val_df['category'])
    return train_df, val_df, test_df


# U-Net Model Architecture
def unet_model(input_size=(256, 256, 3)):
    inputs = Input(input_size)

    # Contracting Path
    c1 = Conv2D(64, (3, 3), activation='relu', padding='same')(inputs)
    c1 = Conv2D(64, (3, 3), activation='relu', padding='same')(c1)
    p1 = MaxPooling2D((2, 2))(c1)

    c2 = Conv2D(128, (3, 3), activation='relu', padding='same')(p1)
    c2 = Conv2D(128, (3, 3), activation='relu', padding='same')(c2)
    p2 = MaxPooling2D((2, 2))(c2)

    c3 = Conv2D(256, (3, 3), activation='relu', padding='same')(p2)
    c3 = Conv2D(256, (3, 3), activation='relu', padding='same')(c3)
    p3 = MaxPooling2D((2, 2))(c3)

    c4 = Conv2D(512, (3, 3), activation='relu', padding='same')(p3)
    c4 = Conv2D(512, (3, 3), activation='relu', padding='same')(c4)
    p4 = MaxPooling2D((2, 2))(c4)

    # Bottleneck
    c5 = Conv2D(1024, (3, 3), activation='relu', padding='same')(p4)
    c5 = Conv2D(1024, (3, 3), activation='relu', padding='same')(c5)

    # Expanding Path
    u6 = Conv2DTranspose(512, (2, 2), strides=(2, 2), padding='same')(c5)
    u6 = concatenate([u6, c4])
    c6 = Conv2D(512, (3, 3), activation='relu', padding='same')(u6)
    c6 = Conv2D(512, (3, 3), activation='relu', padding='same')(c6)

        # Expanding Path continuation
    u7 = Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(c6)
    u7 = concatenate([u7, c3])
    c7 = Conv2D(256, (3, 3), activation='relu', padding='same')(u7)
    c7 = Conv2D(256, (3, 3), activation='relu', padding='same')(c7)

    u8 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c7)
    u8 = concatenate([u8, c2])
    c8 = Conv2D(128, (3, 3), activation='relu', padding='same')(u8)
    c8 = Conv2D(128, (3, 3), activation='relu', padding='same')(c8)

    u9 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c8)
    u9 = concatenate([u9, c1], axis=3)
    c9 = Conv2D(64, (3, 3), activation='relu', padding='same')(u9)
    c9 = Conv2D(64, (3, 3), activation='relu', padding='same')(c9)

    # Output Layer
    outputs = Conv2D(1, (1, 1), activation='sigmoid')(c9)
    model = Model(inputs, outputs)
    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[dice_coefficient])
    return model

# Dice Coefficient as a metric
def dice_coefficient(y_true, y_pred, smooth=1):
    y_true_f = K_flatten(y_true)
    y_pred_f = K_flatten(y_pred)
    intersection = K_sum(y_true_f * y_pred_f)
    return (2. * intersection + smooth) / (K_sum(y_true_f) + K_sum(y_pred_f) + smooth)

# Function to calculate confusion matrix
def calculate_confusion_matrix(generator, model, threshold=0.5):
    true_labels = []
    predicted_labels = []

    for images, masks in generator:
        preds = (model.predict(images) > threshold).astype(int)

        for mask, pred in zip(masks, preds):
            true_labels.append(mask.flatten())
            predicted_labels.append(pred.flatten())

    cm = confusion_matrix(np.concatenate(true_labels), np.concatenate(predicted_labels))
    return cm

from sklearn.metrics import confusion_matrix, classification_report
import numpy as np
import gc
from tensorflow.keras import backend as K

def update_confusion_matrix(cm, y_true, y_pred):
    """Update the confusion matrix with new batch results."""
    cm += confusion_matrix(y_true, y_pred, labels=[0, 1])
    return cm

def batch_confusion_matrix(generator, model, threshold=0.5):
    """Accumulate confusion matrix across batches."""
    cm = np.zeros((2, 2), dtype=int)  # Adjust this shape to match your class count

    for images, masks in generator:
        preds = (model.predict(images) > threshold).astype(int)

        for mask, pred in zip(masks, preds):
            # Flatten and compute confusion matrix for each batch
            true_labels = mask.flatten()
            pred_labels = pred.flatten()
            cm = update_confusion_matrix(cm, true_labels, pred_labels)

    return cm

# import gc

# def clear_memory():
#     gc.collect()

# Prepare the data and split it
data_dir = '/tmp/COVID-19_Radiography_Dataset'
df = prepare_data(data_dir)
train_df, val_df, test_df = prepare_and_split_data(df, test_size=0.1, val_size=0.1)

# Initialize generators
train_gen = ImageMaskGenerator(train_df, image_size=(256, 256), batch_size=32, shuffle=True)
val_gen = ImageMaskGenerator(val_df, image_size=(256, 256), batch_size=32, shuffle=False)
test_gen = ImageMaskGenerator(test_df, image_size=(256, 256), batch_size=32, shuffle=False)


# Ensure model loss matches the input shape
unet = unet_model(input_size=(256, 256, 3))
unet.compile(optimizer='adam', loss='binary_crossentropy', metrics=[dice_coefficient])
unet.summary()

# Training with proper callbacks
checkpoint = ModelCheckpoint('best_model.h5', save_best_only=True)
early_stop = EarlyStopping(patience=3, restore_best_weights=True)

history = unet.fit(train_gen, validation_data=val_gen, epochs=14, verbose=1, callbacks=[checkpoint, early_stop])

# Function to calculate precision, recall, f1, and accuracy from a confusion matrix
def calculate_metrics_from_cm(cm):
    """Calculates metrics from a confusion matrix assuming a binary classification."""
    # True Positives, False Positives, False Negatives, and True Negatives
    tp = cm[1, 1]
    fp = cm[0, 1]
    fn = cm[1, 0]
    tn = cm[0, 0]

    # Calculate metrics
    precision = tp / (tp + fp) if (tp + fp) != 0 else 0
    recall = tp / (tp + fn) if (tp + fn) != 0 else 0
    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) != 0 else 0
    accuracy = (tp + tn) / cm.sum() if cm.sum() != 0 else 0

    return precision, recall, f1, accuracy

# Calculate confusion matrices
train_cm = batch_confusion_matrix(train_gen, unet)
val_cm = batch_confusion_matrix(val_gen, unet)
test_cm = batch_confusion_matrix(test_gen, unet)

# Evaluate on test data
test_loss, test_accuracy = unet.evaluate(test_gen, verbose=0)
print(f"Test Loss: {test_loss}, Test Accuracy: {test_accuracy}")

print("Train Set Confusion Matrix:")
print(train_cm)

print("Validation Set Confusion Matrix:")
print(val_cm)

print("Test Set Confusion Matrix:")
print(test_cm)

# clear_memory()

# Evaluate on test data
# test_loss, test_accuracy = unet.evaluate(test_gen, verbose=0)
# print(f"Test Loss: {test_loss}, Test Accuracy: {test_accuracy}")

# Print confusion matrices and metrics for each set
for name, cm in [('Train', train_cm), ('Validation', val_cm), ('Test', test_cm)]:
    precision, recall, f1, accuracy = calculate_metrics_from_cm(cm)
    print(f"{name} Set Confusion Matrix:")
    print(cm)
    print(f"{name} Set Metrics: Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1:.4f}, Accuracy: {accuracy:.4f}\n")

plot_segmentation_training(history)

# Visualization function after training
def visualize_predictions(generator, model, num_samples=3):
    plt.figure(figsize=(12, 10))
    for i, (images, masks) in enumerate(generator):
        if i >= num_samples:
            break
        preds = model.predict(images)
        for j in range(len(images)):
            plt.subplot(num_samples, 3, i * 3 + 1)
            plt.imshow(images[j])
            plt.title('Original Image')
            plt.axis('off')

            plt.subplot(num_samples, 3, i * 3 + 2)
            plt.imshow(masks[j].squeeze(), cmap='gray')
            plt.title('True Mask')
            plt.axis('off')

            plt.subplot(num_samples, 3, i * 3 + 3)
            pred = (preds[j].squeeze() > 0.5).astype(np.float32)
            plt.imshow(pred, cmap='gray')
            plt.title('Predicted Mask')
            plt.axis('off')
    plt.show()

# Call to visualize predictions on validation data
visualize_predictions(val_gen, unet, num_samples=3)

import matplotlib.pyplot as plt
import numpy as np

def visualize_predictions_with_overlay(generator, model, num_samples=3):
    plt.figure(figsize=(15, 5 * num_samples))
    for i, (images, masks) in enumerate(generator):
        if i >= num_samples:
            break
        preds = model.predict(images)
        for j in range(len(images)):
            plt.subplot(num_samples, 3, i * 3 + 1)
            plt.imshow(images[j])
            plt.title('Original Image')
            plt.axis('off')

            plt.subplot(num_samples, 3, i * 3 + 2)
            plt.imshow(masks[j].squeeze(), cmap='gray')
            plt.title('True Mask')
            plt.axis('off')

            plt.subplot(num_samples, 3, i * 3 + 3)
            plt.imshow(images[j])
            plt.imshow((preds[j].squeeze() > 0.5).astype(np.float32), cmap='jet', alpha=0.5)  # Overlay mask
            plt.title('Overlay Predicted Mask')
            plt.axis('off')
    plt.show()

# Call to visualize predictions with overlay on validation data
visualize_predictions_with_overlay(val_gen, unet, num_samples=3)

tf.keras.utils.plot_model(unet, show_shapes=True)

# Define model name for the experiment results
model_name = "U-Net Model"

# Initialize a list to store results
results = []

# Iterate through each set and collect results
for set_name, cm in [('Train', train_cm), ('Validation', val_cm), ('Test', test_cm)]:
    precision, recall, f1, accuracy = calculate_metrics_from_cm(cm)
    result = {
        'Experiment ID': "1",
        'Model': model_name,
        'Set': set_name,
        'Accuracy': accuracy,
        'Precision': precision,
        'Recall': recall,
        'F1 Score': f1
    }
    results.append(result)

# Convert results to DataFrame
results_df = pd.DataFrame(results)

# Export to Excel
results_df.to_excel('experiment_results.xlsx', index=False)

# Download the file to your local system
files.download('experiment_results.xlsx')
